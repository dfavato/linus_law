{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linusâ€™s Law: More Eyes Fewer Flaws in Open Source Projects\n",
    "\n",
    "Danilo Favato, Daniel Ishitani, Johnatan Oliveira, Eduardo Figueiredo\n",
    "\n",
    "Department of Computer Science, Federal University of Minas Gerais (UFMG)\n",
    "\n",
    "Belo Horizonte, Brazil\n",
    "\n",
    "This Python notebook reproduce our sampling steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main study methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import requests  # External lib, requires installation\n",
    "\n",
    "from collections import defaultdict\n",
    "import pandas as pd  # External lib, requires installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling\n",
    "\n",
    "**Caution**:\n",
    "As we cannot control GitHub search API and projects evolution the steps below may generate a different sample from the one used in the original study. If you want to use the exact data sampled by the authors skip to the SonarQube Analysis.\n",
    "\n",
    "We tried to avoid selection bias by employing a method that tried to be as closer to a simple random sampling as possible.\n",
    "\n",
    "GitHub API returns only the first 1000 results which are paginated in pages of size 30. We generated a sequence of 100 numbers from 0 to 1000, without reposition. Then we calculated the page and position within the page for each of the numbers in the sequence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(27091989)\n",
    "items = random.sample(range(0, 1000), 100)\n",
    "items.sort()\n",
    "sample_pages = defaultdict(list)\n",
    "for item in items:\n",
    "    sample_pages[item // 30 + 1].append(item % 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Querying GitHub API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = []\n",
    "for page in sample_pages:\n",
    "    search_url = f'https://api.github.com/search/repositories?page={page}&q=python+language:python'\n",
    "    r = requests.get(search_url)\n",
    "    while not r.ok:\n",
    "        time.sleep(10)\n",
    "        r = requests.get(search_url)\n",
    "    for item in sample_pages[page]:\n",
    "        sample.append(r.json()['items'][item])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving selected projects. Uncomment if you wish to overwrite original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('sample.json', 'w') as f:\n",
    "#    f.write(json.dumps(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cloning every project. Uncomment if you wish to overwrite original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_field = 'full_name'\n",
    "url_field = 'git_url'\n",
    "for row in df.itertuples():\n",
    "    project_folder = 'projects/' + row.full_name.split('/')[0]\n",
    "#    !mkdir -p {project_folder}\n",
    "#    !git -C {project_folder} clone {row.git_url} --depth=1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SonarQube Analysis\n",
    "\n",
    "**Requirements:** You must have a SonarQube instance running on http://localhost:9000 that can be accessed with the credentials admin:admin\n",
    "\n",
    "**Caution:** Using a different version or quality profile may change the results obtained by the authors. In the original study SonarQube version 7.7 with the standard Python quality profile was used. If you wish to use the exact same data used in the original study proceed to the Statistical Analysis section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load sampled projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sample.json', 'r') as f:\n",
    "    sample = json.load(f)\n",
    "df = pd.DataFrame.from_records(sample)\n",
    "df['project_name'] = df.apply(lambda x: x['full_name'].replace('/', '.'), axis=1)\n",
    "df.set_index('project_name', inplace=True)\n",
    "fields = [\n",
    "    'size', 'open_issues', 'forks', 'watchers'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the source code from the compressed file, or not, if you have downloaded it yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat projects_source_code.tar.7z.parta* > projects_source_code.tar.7z\n",
    "!7z x -so projects_source_code.tar.7z | tar xf - -C ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the projects in SonarQube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df.itertuples():\n",
    "    project_name = row.full_name.replace('/', '.')\n",
    "    !curl -u admin:admin -X POST 'http://localhost:9000/api/projects/create?key={project_name}&name={project_name}' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the Sonar-Scanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df.itertuples():\n",
    "    project_name = row.full_name.replace('/', '.')\n",
    "    project_folder = 'projects/' + row.full_name.split('/')[0]\n",
    "    !sonar-scanner -Dsonar.projectKey={project_name} -Dsonar.sources={project_folder} -Dsonar.host.url=http://localhost:9000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract analysis results from SonarQube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = (\n",
    "    'ncloc',\n",
    "    'complexity',\n",
    "    'duplicated_lines_density',\n",
    "    'sqale_rating',\n",
    "    'sqale_index',\n",
    "    'sqale_debt_ratio',\n",
    "    'reliability_remediation_effort',\n",
    "    'security_remediation_effort'\n",
    ")\n",
    "_metrics = ','.join(metrics)\n",
    "\n",
    "test_data = []\n",
    "for row in df.itertuples():\n",
    "    project_key = row.full_name.replace('/', '.')\n",
    "    url = f'http://localhost:9000/api/measures/search?projectKeys={project_key}&metricKeys={_metrics}'\n",
    "    r = requests.get(url)\n",
    "    measures = r.json()['measures']\n",
    "    for m in measures:\n",
    "        test_data.append({\n",
    "            'project': m['component'],\n",
    "            'metric': m['metric'],\n",
    "            'value': float(m['value'])\n",
    "        })\n",
    "        \n",
    "TYPES = ('CODE_SMELL', 'BUG')\n",
    "SEVERITIES = ('BLOCKER', 'CRITICAL', 'MAJOR', 'MINOR', 'INFO')\n",
    "issues_data = []\n",
    "for row in df.itertuples():\n",
    "    project_key = row.full_name.replace('/', '.')\n",
    "    project_metrics = {'project_key': project_key}\n",
    "    for t in TYPES:\n",
    "        for s in SEVERITIES:\n",
    "            url = f'http://localhost:9000/api/issues/search?componentKeys={project_key}&languages=py&types={t}&severities={s}'\n",
    "            r = requests.get(url)\n",
    "            project_metrics['_'.join((t, s)).lower()] = r.json()['total']\n",
    "    issues_data.append(project_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_df = pd.DataFrame(\n",
    "    issues_data, index=[x['project_key'] for x in issues_data]\n",
    ")\n",
    "\n",
    "stat_df = pd.merge(\n",
    "    df[fields],\n",
    "    issues_df,\n",
    "    how='left', left_index=True, right_index=True\n",
    ").drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save results. Uncomment if you wish to overwrite original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#stat_df.to_excel('data.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to the R notebook for the Statistial Analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
